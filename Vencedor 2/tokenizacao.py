#encoding: utf-8
#import os, sys
#import gensim, logging
#from gensim.models import Word2Vec
#from pprint import pprint
#import codecs
#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

def tokenize(line):
    line=line.replace(","," ")
    line=line.replace("."," ")
    line=line.replace("'"," ")
    line=line.replace('"'," ")
    line=line.replace(">"," ")
    line=line.replace("<"," ")
    line=line.replace(";"," ")
    line=line.replace("="," ")
    line=line.replace("!"," ")
    line=line.replace("?"," ")
    line=line.replace("("," ")
    line=line.replace(")"," ")
    line=line.replace(":"," ")
    line=line.replace("["," ")
    line=line.replace("]"," ")
    line=line.replace(u"´"," ")
    line=line.replace("#"," ")
    line=line.replace(u"`"," ")
    line=line.replace("{"," ")
    line=line.replace("}"," ")
    line=line.lower()
    line=line.replace(u"á","a")
    line=line.replace(u"à","a")
    line=line.replace(u"ã","a")
    line=line.replace(u'â',"a")
    line=line.replace(u"ä","a")
    line=line.replace(u"é","e")
    line=line.replace(u"è","e")
    line=line.replace(u"ê","e")
    line=line.replace(u"ë","e")
    line=line.replace(u"í","i")
    line=line.replace(u"ì","i")
    line=line.replace(u'î',"i")
    line=line.replace(u"ï","i")
    line=line.replace(u"ó","o")
    line=line.replace(u"ò","o")
    line=line.replace(u"õ","o")
    line=line.replace(u'ô',"o")
    line=line.replace(u"ö","o")
    line=line.replace(u"ú","u")
    line=line.replace(u"ù","u")
    line=line.replace(u"û","u")
    line=line.replace(u'ü',"u")
    line=line.replace(u"ç","c")
    return line
